[project]
name = "parallel-decoder-transformer"
version = "0.1.0"
description = "Toy Parallel Decoder Transformer architecture scaffold inspired by DeepSeek."
readme = "README.md"
requires-python = ">=3.12"
authors = [
  { name = "Logan Robbins" }
]
license = { text = "MIT" }
keywords = ["transformer", "multistream", "deepseek", "ml"]

# Core dev dependencies kept lightweight for macOS CPU iteration.
dependencies = [
  "pydantic>=2.9.0",
  "omegaconf>=2.3.0",
  "matplotlib>=3.10.6",
  "transformers>=4.56.2",
  # Torch GPU is the only runtime requirement; keep flexible across Lambda images
  "torch>=2.8,<3.0",
  "tiktoken>=0.7.0",
  "protobuf>=4.25.3",
  "accelerate>=0.34.2",
  "pandoc>=2.4",
  "numpy>=1.26",
  "pyarrow>=16.0",
  "sentence-transformers>=3.0",
  "ray[default]>=2.24",
  "requests>=2.32",
  "tqdm>=4.66",
  "python-dotenv>=1.0",
  "openai>=2.7.2",
  "datasets>=2.20",
  "reasoning-gym>=0.1.24",
  "wandb>=0.23.0",
  "httpx>=0.28.1",
  "jsonschema>=4.25.1",
  "aiohttp>=3.13.2",
]

[project.optional-dependencies]
test = [
  "pytest>=8.2",
  "pytest-cov>=5.0",
]
notebook = [
  "jupyterlab>=4.2",
]
# Data ingestion and preprocessing dependencies.
data = [
  "datasets>=2.20",
  "transformers>=4.44",
  "sentence-transformers>=3.0",
  "pyarrow>=16.0",
  "ray[default]>=2.24",
  "numpy>=1.26",
  "tqdm>=4.66",
]
# GPU stack to be installed on CUDA hosts only.
gpu = [
  # No extra packages required beyond core `torch` for this codebase
]

[dependency-groups]
dev = [
  "ruff>=0.6.3",
  "mypy>=1.11",
  "pytest>=8.4.2",
  "pytest-cov>=7.0.0",
  "black>=25.12.0",
]

[tool.ruff]
line-length = 100
src = ["src"]

[tool.pytest.ini_options]
minversion = "8.2"
addopts = "-ra --showlocals"
testpaths = ["tests"]
