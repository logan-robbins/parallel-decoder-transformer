# Data Directory Structure

This directory contains all data-related files for the Parallel Decoder Transformer project.

## Directory Organization

```
data/
├── DATASET_PIPELINE.md     # Complete dataset generation documentation
├── TRAINING.md              # Complete training documentation
├── raw/                     # Raw source data (gitignored)
├── prep/                    # Intermediate pipeline outputs (gitignored)
│   ├── preflight/          # Stage 1: Validated Wikipedia articles
│   ├── plans/              # Stage 2: Generated 3-stream plans
│   └── notes/              # Stage 3: True/speculative notes
├── datasets/                # Stage 4: Final Parquet splits (gitignored)
├── processed/               # Stage 5: Training-ready JSONL (gitignored)
├── manifests/               # Source data manifests (checked in)
└── teacher_cache/           # Cached teacher logits (gitignored)
```

## What's Checked In

- **Directory structure**: Empty directories with `.gitkeep` files
- **Manifests**: Wikipedia and source data references in `manifests/`
- **Documentation**: `DATASET_PIPELINE.md` and `TRAINING.md`

## What's Ignored

- All actual data files in `prep/`, `datasets/`, `processed/`, and `teacher_cache/`
- These directories can be regenerated by following the pipeline documentation

## Getting Started

1. **Dataset generation**: See `DATASET_PIPELINE.md` for the 5-stage pipeline
2. **Training**: See `TRAINING.md` for curriculum and deployment instructions

## Data Flow

```
Wikipedia articles
    ↓
[Stage 1: Preflight] → data/prep/preflight/
    ↓
[Stage 2: Plans] → data/prep/plans/
    ↓
[Stage 3: Notes] → data/prep/notes/
    ↓
[Stage 4: Collation] → data/datasets/
    ↓
[Stage 5: KD Export] → data/processed/
    ↓
Training (reads from data/processed/)
```

