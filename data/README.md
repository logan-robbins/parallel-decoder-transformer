# Data Directory Structure

This directory contains all data-related files for the Parallel Decoder Transformer project.

## Pre-Generated Data Available

Pre-generated datasets and artifacts are publicly available at:

**https://storage.googleapis.com/parallel-decoder-transformer/data/archives/**

Download ready-to-use training data instead of running the full pipeline:
- `pdt_10k_gpt41_jsonl_train.tar.gz` - Training split (2.7GB)
- `pdt_10k_gpt41_jsonl_eval.tar.gz` - Validation/test splits (647MB)
- `pdt_10k_gpt41_parquet.tar.gz` - Parquet format (2.1GB)
- `pdt_10k_plans.tar.gz` - Plans only (129MB)

See `DATASET_PIPELINE.md` for download instructions.

## Directory Organization

```
data/
├── DATASET_PIPELINE.md     # Complete dataset generation documentation
├── TRAINING.md              # Complete training documentation
├── raw/                     # Raw source data (gitignored)
├── prep/                    # Intermediate pipeline outputs (gitignored)
│   ├── preflight/          # Stage 1: Validated Wikipedia articles
│   ├── plans/              # Stage 2: Generated 3-stream plans
│   └── notes/              # Stage 3: True/speculative notes
├── datasets/                # Stage 4: Final Parquet splits (gitignored)
├── processed/               # Stage 5: Training-ready JSONL (gitignored)
├── manifests/               # Source data manifests (checked in)
└── teacher_cache/           # Cached teacher logits (gitignored)
```

## What's Checked In

- **Directory structure**: Empty directories with `.gitkeep` files
- **Manifests**: Wikipedia and source data references in `manifests/`
- **Documentation**: `DATASET_PIPELINE.md` and `TRAINING.md`

## What's Ignored

- All actual data files in `prep/`, `datasets/`, `processed/`, and `teacher_cache/`
- These directories can be regenerated by following the pipeline documentation

## Getting Started

1. **Dataset generation**: See `DATASET_PIPELINE.md` for the 5-stage pipeline
2. **Training**: See `TRAINING.md` for curriculum and deployment instructions

## Data Flow

```
Wikipedia articles
    ↓
[Stage 1: Preflight] → data/prep/preflight/
    ↓
[Stage 2: Plans] → data/prep/plans/
    ↓
[Stage 3: Notes] → data/prep/notes/
    ↓
[Stage 4: Collation] → data/datasets/
    ↓
[Stage 5: KD Export] → data/processed/
    ↓
Training (reads from data/processed/)
```

