@inproceedings{Ainslie2023,
  author = {Ainslie, J. and Lee-Thorp, J. and de Jong, M. and Zemlyanskiy, Y. and Lebrón, F. and Sanghai, S.},
  title = {GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
  booktitle = {Proceedings of EMNLP 2023},
  year = {2023},
  note = {arXiv:2305.13245}
}

@article{Beltagy2020,
  author = {Beltagy, I. and Peters, M. E. and Cohan, A.},
  title = {Longformer: The Long-Document Transformer},
  journal = {arXiv preprint arXiv:2004.05150},
  year = {2020}
}

@article{Dai2019,
  author = {Dai, Z. and Yang, Z. and Yang, Y. and Carbonell, J. and Le, Q. V. and Salakhutdinov, R.},
  title = {Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context},
  journal = {arXiv preprint arXiv:1901.02860},
  year = {2019}
}

@article{Dao2023,
  author = {Dao, T. and Fu, D. Y. and Ermon, S. and Rudra, A. and Ré, C.},
  title = {FlashAttention-2: Faster Attention with Better Memory Utilization},
  journal = {arXiv preprint arXiv:2307.08691},
  year = {2023}
}

@article{cai2024medusa,
  author = {Cai, T. and others},
  title = {Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads},
  journal = {arXiv preprint arXiv:2401.10774},
  year = {2024}
}

@article{EAGLE2024,
  author = {Sun, Z. and others},
  title = {EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty},
  journal = {arXiv preprint arXiv:2401.15077},
  year = {2024}
}

@inproceedings{PSLM2024,
  author = {Liu, X. and others},
  title = {PSLM: Parallel Generation of Text and Speech with LLMs},
  booktitle = {Findings of EMNLP 2024},
  year = {2024}
}

@article{Goyal2021,
  author = {Goyal, A. and others},
  title = {Coordination Among Neural Modules Through a Shared Workspace},
  journal = {arXiv preprint arXiv:2103.01197},
  year = {2021}
}

@article{Vapnik2015,
  author = {Vapnik, V.},
  title = {Learning Using Privileged Information: Similarity Control and Knowledge Transfer},
  journal = {Journal of Machine Learning Research},
  volume = {16},
  year = {2015}
}

@inproceedings{LopezPaz2015,
  author = {Lopez-Paz, D. and Bottou, L. and Schölkopf, B. and Vapnik, V.},
  title = {Unifying Distillation and Privileged Information},
  booktitle = {ICLR Workshop},
  year = {2016}
}

@article{Deng2025,
  author = {Deng, J.},
  title = {Latent Reasoning in LLMs as a Vocabulary-Space Superposition},
  journal = {arXiv preprint arXiv:2510.15522},
  year = {2025}
}

@inproceedings{Geifman2017,
  author = {Geifman, Y. and El-Yaniv, R.},
  title = {Selective classification for deep neural networks},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS 2017)},
  year = {2017},
  note = {arXiv:1705.08500}
}

@inproceedings{Kwon2023,
  author = {Kwon, W. and Li, Z. and Zhuang, S. and Sheng, Y. and Zheng, L. and Yu, C. H. and Gonzalez, J. and Zhang, H. and Stoica, I.},
  title = {Efficient memory management for large language model serving with PagedAttention},
  booktitle = {Proceedings of SOSP 2023},
  year = {2023},
  note = {arXiv:2309.06180}
}

@article{Liu2025a,
  author = {Liu, X. and others},
  title = {ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference},
  journal = {arXiv preprint arXiv:2502.00299},
  year = {2025}
}

@article{Liu2025b,
  author = {Liu, X. and others},
  title = {ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs},
  journal = {arXiv preprint arXiv:2503.10714},
  year = {2025}
}

@article{ning2023skeleton,
  author = {Ning, X. and Lin, Z. and Yang, H. and Wang, Y.},
  title = {Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation},
  journal = {arXiv preprint arXiv:2307.15337},
  year = {2023}
}

@article{Ren2023,
  author = {Ren, A. and Li, B. and Sun, R. and Liu, T.},
  title = {Calibrating Large Language Models with Handcrafted Augmentation},
  journal = {arXiv preprint arXiv:2310.05417},
  year = {2023}
}

@article{Stern2018,
  author = {Stern, M. and Shazeer, N. and Uszkoreit, J.},
  title = {Blockwise Parallel Decoding for Deep Autoregressive Models},
  journal = {arXiv preprint arXiv:1811.03115},
  year = {2018}
}

@article{Yan2024,
  author = {Yan, M. and others},
  title = {Decoding Speculative Decoding},
  journal = {arXiv preprint arXiv:2402.01528},
  year = {2024}
}

@article{Yoshikawa2023,
  author = {Yoshikawa, S. and Okazaki, N.},
  title = {Selective Generation for Pass-fail Evaluation},
  journal = {arXiv preprint arXiv:2311.08803},
  year = {2023}
}

@article{survey2025,
  author = {Zhang, L. and Fang, L. and Duan, C. and He, M. and Pan, L. and Xiao, P. and Huang, S. and Zhai, Y. and Hu, X. and Yu, P. S. and Liu, A.},
  title = {A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models},
  journal = {arXiv preprint arXiv:2508.08712},
  year = {2025}
}

@inproceedings{Li2024lookahead,
  author = {Li, Y. and Wei, F. and Zhang, C. and Zhang, H.},
  title = {Break the Sequential Dependency of LLM Inference Using Lookahead Decoding},
  booktitle = {Proceedings of ICML 2024},
  year = {2024},
  note = {arXiv:2402.02057}
}

@article{Rodionov2025,
  author = {Rodionov, A. and others},
  title = {Hogwild! Inference: Parallel LLM Generation via Concurrent Attention},
  journal = {arXiv preprint arXiv:2504.06261},
  year = {2025}
}

@article{Xiao2025sprint,
  author = {Xiao, G. and others},
  title = {SPRINT: Enabling Interleaved Planning and Parallelized Execution in Large Reasoning Models},
  journal = {arXiv preprint arXiv:2506.05745},
  year = {2025}
}

@article{Zheng2025,
  author = {Zheng, L. and others},
  title = {Semantic Reflective Verification for Faster Speculative Decoding},
  journal = {arXiv preprint arXiv:2505.18629},
  year = {2025}
}

@article{Wei2025sidechannel,
  author = {Wei, J. and others},
  title = {Side-Channel Attacks on Speculative Decoding in LLMs},
  journal = {arXiv preprint arXiv:2411.01076},
  year = {2025}
}

@inproceedings{Chen2018,
  author = {Chen, Z. and Badrinarayanan, V. and Lee, C.-Y. and Rabinovich, A.},
  title = {GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks},
  booktitle = {Proceedings of ICML 2018},
  year = {2018},
  note = {arXiv:1711.02257}
}

@inproceedings{Miyato2018,
  author = {Miyato, T. and Kataoka, T. and Koyama, M. and Yoshida, Y.},
  title = {Spectral Normalization for Generative Adversarial Networks},
  booktitle = {Proceedings of ICLR 2018},
  year = {2018},
  note = {arXiv:1802.05957}
}

@inproceedings{Fazlyab2019,
  author = {Fazlyab, M. and Robey, A. and Hassani, H. and Morari, M. and Pappas, G. J.},
  title = {Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks},
  booktitle = {Proceedings of NeurIPS 2019},
  year = {2019},
  note = {arXiv:1906.04893}
}

@misc{snc_code,
  author = {Robbins, L.},
  title = {Parallel Decoder Transformer Codebase},
  year = {2025},
  url = {https://github.com/logan-robbins/parallel-decoder-transformer}
}

@inproceedings{leviathan2023fast,
  title={Fast Inference from Transformers via Speculative Decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  year={2023}
}

@inproceedings{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-Efficient Transfer Learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morri, Bruna and De Coro, Andrea and Vassilvitskii, Sergei and Fisher, Ariel and Ganguli, Deep},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@inproceedings{bulatov2022recurrent,
  title={Recurrent Memory Transformer},
  author={Bulatov, Aydar and Kuratov, Yuri and Burtsev, Mikhail},
  booktitle={NeurIPS},
  year={2022}
}

@article{gu2023mamba,
  title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@inproceedings{bachlechner2021rezero,
  title={ReZero is All You Need: Fast Convergence at Large Depth},
  author={Bachlechner, Thomas and Majumder, Bodhisattwa Prasad and Mao, Henry and Cottrell, Garrison W and McAuley, Julian},
  booktitle={Uncertainty in Artificial Intelligence},
  year={2021}
}
